{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(r\"data\\train.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data:\n",
    "    img = data[0]\n",
    "    choice = data[1]\n",
    "    cv2.imshow(\"test\", img)\n",
    "    print(choice)\n",
    "    if cv2.waitKey(25) & 0XFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data\\test.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalancing data so that it's not all just driving forward examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...   \n",
       "1  [[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...   \n",
       "2  [[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...   \n",
       "3  [[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...   \n",
       "4  [[28, 67, 97, 97, 97, 113, 116, 97, 97, 97, 97...   \n",
       "\n",
       "                             1  \n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_key(vector):\n",
    "    mapping = {\n",
    "        0: 'w',\n",
    "        1: 's',\n",
    "        2: 'a',\n",
    "        3: 'd',\n",
    "        4: 'wa',\n",
    "        5: 'wd',\n",
    "        6: 'sa',\n",
    "        7: 'sd',\n",
    "        8: 'nk'\n",
    "    }\n",
    "    return mapping[np.argmax(vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w 6780\n",
      "nk 5494\n",
      "wd 1034\n",
      "wa 1009\n",
      "d 713\n",
      "a 668\n",
      "s 245\n",
      "sa 46\n",
      "sd 11\n"
     ]
    }
   ],
   "source": [
    "for value, count in df[1].value_counts().items():\n",
    "    print(output_to_key(value), count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = np.load(r\"data\\train2.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(np.concatenate((train_data, train_data2), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w 7047\n",
      "nk 6113\n",
      "wa 1335\n",
      "wd 1139\n",
      "d 867\n",
      "a 790\n",
      "s 737\n",
      "sd 690\n",
      "sa 282\n"
     ]
    }
   ],
   "source": [
    "for value, count in combined_df[1].value_counts().items():\n",
    "    print(output_to_key(value), count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "train_data = np.concatenate((train_data, train_data2), axis=0)\n",
    "lefts = []\n",
    "rights = []\n",
    "forwards = []\n",
    "backwards = []\n",
    "leftforwards = []\n",
    "rightforwards = []\n",
    "leftbacks = []\n",
    "rightbacks = []\n",
    "nokeys = []\n",
    "\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa =[0,0,0,0,1,0,0,0,0]\n",
    "wd =[0,0,0,0,0,1,0,0,0]\n",
    "sa =[0,0,0,0,0,0,1,0,0]\n",
    "sd =[0,0,0,0,0,0,0,1,0]\n",
    "nk =[0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "shuffle(train_data)\n",
    "\n",
    "for data in train_data:\n",
    "    img = data[0]\n",
    "    choice = data[1]\n",
    "\n",
    "    if choice == w:\n",
    "        forwards.append([img, choice])\n",
    "    elif choice == s:\n",
    "        backwards.append([img, choice])\n",
    "    elif choice == a:\n",
    "        lefts.append([img, choice])\n",
    "    elif choice == d:\n",
    "        rights.append([img, choice])\n",
    "    elif choice == wa:\n",
    "        leftforwards.append([img, choice])\n",
    "    elif choice == wd:\n",
    "        rightforwards.append([img, choice])\n",
    "    elif choice == sa:\n",
    "        leftbacks.append([img, choice])\n",
    "    elif choice == sd:\n",
    "        rightbacks.append([img, choice])\n",
    "    elif choice == nk:\n",
    "        nokeys.append([img, choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# List of all categories\n",
    "categories = [lefts, rights, forwards, backwards, leftforwards, rightforwards, leftbacks, rightbacks, nokeys]\n",
    "\n",
    "# Function to reduce the size of a list to 1000 elements\n",
    "def reduce_to_1000(lst):\n",
    "    while len(lst) > 1000:\n",
    "        # Randomly remove an element\n",
    "        index_to_remove = random.randint(0, len(lst) - 1)\n",
    "        lst.pop(index_to_remove)\n",
    "\n",
    "# Apply the function to each category\n",
    "for category in categories:\n",
    "    reduce_to_1000(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = lefts + rights + forwards + backwards + leftforwards + rightforwards + leftbacks + rightbacks + nokeys\n",
    "shuffle(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_balanced.npy', np.array(final_data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 37.5 MiB for an array with shape (32, 480, 640, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m category])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Augment images until the category reaches 7000 elements\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, _ \u001b[38;5;129;01min\u001b[39;00m datagen\u001b[38;5;241m.\u001b[39mflow(reshaped_images, labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m augmented_image \u001b[38;5;129;01min\u001b[39;00m X_batch:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(category) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m7000\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alex Zavalny\\Desktop\\GTA 5 Self Driving Car\\gta5\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex Zavalny\\Desktop\\GTA 5 Self Driving Car\\gta5\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex Zavalny\\Desktop\\GTA 5 Self Driving Car\\gta5\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:795\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_batches_of_transformed_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_array):\n\u001b[1;32m--> 795\u001b[0m     batch_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[0;32m    799\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 37.5 MiB for an array with shape (32, 480, 640, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initial categories\n",
    "categories = [lefts, rights, backwards, leftforwards, rightforwards, leftbacks, rightbacks, nokeys]\n",
    "\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Assuming all images are of the same size, for example, 480x640\n",
    "image_shape = (480, 640, 1)  # Change this based on your actual image size\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    print(category)\n",
    "    reshaped_images = np.array([img.reshape(image_shape) for img, _ in category])\n",
    "    labels = np.array([label for _, label in category])\n",
    "\n",
    "    augmented_count = 0\n",
    "    for X_batch, _ in datagen.flow(reshaped_images, labels, batch_size=16):\n",
    "        for augmented_image in X_batch:\n",
    "            if augmented_count + len(category) < 7000:\n",
    "                category.append((augmented_image, labels[0]))  # Append augmented image with original label\n",
    "                augmented_count += 1\n",
    "            else:\n",
    "                break\n",
    "        if augmented_count + len(category) >= 7000:\n",
    "            break\n",
    "    \n",
    "    categories[i] = category  # Update the original category with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forwards = forwards[:len(lefts)][:len(rights)]\n",
    "lefts = lefts[:len(forwards)]\n",
    "rights = rights[:len(forwards)]\n",
    "\n",
    "final_data = forwards + lefts + rights\n",
    "shuffle(final_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gta5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
